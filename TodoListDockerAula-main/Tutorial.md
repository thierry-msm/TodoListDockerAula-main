### **üõ† Atividade Pr√°tica: Criando um To-Do List Monol√≠tico**
üìå **Objetivo:** Criar um sistema simples de cadastro de tarefas com funcionalidades de **adicionar, editar, excluir e marcar como conclu√≠do**.

#### **üë®‚Äçüíª Tecnologias recomendadas**
- **Stack b√°sica:** HTML, CSS, JavaScript (para frontend) + Python (Flask) ou Node.js (Express) para o backend.  
- **Banco de dados:** SQLite (simples e n√£o precisa de configura√ß√£o extra).  

---

## **üìå Passo 1: Configurar o Ambiente**
Antes de come√ßar, os alunos devem garantir que t√™m o **Python** instalado. Eles podem verificar isso com:  
```sh
python --version
```
Se Python estiver instalado, deve retornar algo como:  
```
Python 3.x.x
```
Caso contr√°rio, o Python pode ser baixado em: [https://www.python.org/downloads/](https://www.python.org/downloads/).

---

## **üìå Passo 2: Criar um Ambiente Virtual**
√â uma boa pr√°tica criar um **ambiente virtual** para o projeto. Isso evita conflitos entre bibliotecas.  
Execute os comandos:  
```sh
# Criar um ambiente virtual
python -m venv .venv  

# Ativar o ambiente virtual (Windows)
.venv\Scripts\activate  

# Ativar o ambiente virtual (Linux/Mac)
source .venv/bin/activate  
```
O terminal mostrar√° algo como `(.venv)` indicando que o ambiente virtual est√° ativo.

---

## **üìå Passo 3: Instalar as Depend√™ncias**
Dentro do ambiente virtual, instale o Flask:  
```sh
pip install flask
```
Opcionalmente, se quiser salvar as depend√™ncias em um arquivo `requirements.txt`, use:  
```sh
pip freeze > requirements.txt
```
E para instalar a partir dele em outro ambiente:  
```sh
pip install -r requirements.txt
```

---

## **üìå Passo 4: Criar o Banco de Dados**
Crie um script para definir a estrutura do banco.  
Crie o arquivo `init_db.py` e adicione:  
```python
import sqlite3

con = sqlite3.connect("database.db")
cur = con.cursor()
cur.execute("""
CREATE TABLE tasks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    task TEXT NOT NULL,
    completed INTEGER DEFAULT 0
)
""")
con.commit()
con.close()

print("Banco de dados criado com sucesso!")
```
Agora execute:  
```sh
python init_db.py
```
Isso criar√° um arquivo `database.db` com a tabela `tasks`.

---

## **üìå Passo 5: Criar a Aplica√ß√£o Flask**
Agora, crie o arquivo `app.py` com o seguinte c√≥digo:

```python
from flask import Flask, render_template, request, redirect
import socket, os

app = Flask(__name__)

import sqlite3

def connect_db():
    return sqlite3.connect("database.db")

@app.route('/oi')
def hello():
    hostname = socket.gethostname()
    port = os.environ.get('PORT', '5000')  # Pega a porta do ambiente ou usa 5000 como padr√£o
    return f"Hello from {hostname} on port {port}!\n"

@app.route('/')
def index():
    con = connect_db()
    cur = con.cursor()
    cur.execute("SELECT * FROM tasks")
    tasks = cur.fetchall()
    con.close()
    return render_template("index.html", tasks=tasks)

@app.route('/add', methods=['POST'])
def add_task():
    task = request.form['task']
    con = connect_db()
    cur = con.cursor()
    cur.execute("INSERT INTO tasks (task, completed) VALUES (?, ?)", (task, 0))
    con.commit()
    con.close()
    return redirect('/')

@app.route('/delete/<int:id>')
def delete_task(id):
    con = connect_db()
    cur = con.cursor()
    cur.execute("DELETE FROM tasks WHERE id=?", (id,))
    con.commit()
    con.close()
    return redirect('/')

@app.route('/complete/<int:id>')
def complete_task(id):
    con = connect_db()
    cur = con.cursor()
    cur.execute("UPDATE tasks SET completed = 1 WHERE id=?", (id,))
    con.commit()
    con.close()
    return redirect('/')

if __name__ == "__main__":
    app.run(debug=True)
```
Esse c√≥digo cria uma API simples com as seguintes rotas:
- `/` ‚Üí Exibe a lista de tarefas.
- `/add` ‚Üí Adiciona uma nova tarefa.
- `/delete/<id>` ‚Üí Exclui uma tarefa.
- `/complete/<id>` ‚Üí Marca uma tarefa como conclu√≠da.

---

## **üìå Passo 6: Criar o Frontend**
Crie uma pasta chamada `templates` e dentro dela um arquivo `index.html`:

```html
<!DOCTYPE html>
<html lang="pt">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Lista de Tarefas</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 500px; margin: auto; text-align: center; }
        ul { list-style: none; padding: 0; }
        li { padding: 10px; border: 1px solid #ddd; margin: 5px 0; display: flex; justify-content: space-between; }
        .completed { text-decoration: line-through; color: gray; }
    </style>
</head>
<body>
    <h1>Lista de Tarefas</h1>
    <form action="/add" method="POST">
        <input type="text" name="task" required>
        <button type="submit">Adicionar</button>
    </form>
    <ul>
        {% for task in tasks %}
            <li class="{% if task[2] == 1 %}completed{% endif %}">
                {{ task[1] }}  
                <a href="/complete/{{ task[0] }}">‚úîÔ∏è</a>
                <a href="/delete/{{ task[0] }}">‚ùå</a>
            </li>
        {% endfor %}
    </ul>
</body>
</html>
```
Esse frontend:\
‚úÖ Exibe as tarefas  
‚úÖ Permite adicionar novas  
‚úÖ Permite marcar como conclu√≠das  
‚úÖ Permite excluir  

---

## **üìå Passo 7: Executar a Aplica√ß√£o**
Para rodar o servidor Flask, execute:  
```sh
python app.py
```
Agora acesse no navegador:  
üëâ `http://127.0.0.1:5000/`  

---

Para escalar sua aplica√ß√£o Flask monol√≠tica, voc√™ pode adotar estrat√©gias que melhorem o desempenho e permitam que mais usu√°rios acessem simultaneamente. Vou dividir as solu√ß√µes em **escalabilidade vertical** e **escalabilidade horizontal**, al√©m de outras otimiza√ß√µes.  

---

# **1Ô∏è‚É£ Escalabilidade Vertical (Aumentar Recursos do Servidor)**
A escalabilidade **vertical** significa **melhorar o servidor** onde sua aplica√ß√£o est√° rodando. Isso inclui:  
‚úÖ **Usar um servidor mais potente** (mais CPU, RAM)  
‚úÖ **Usar um banco de dados externo** (ex: PostgreSQL no RDS da AWS)  
‚úÖ **Configurar um WSGI mais eficiente**, como **Gunicorn**  

### **üîß Usando Gunicorn**

WSGI (Web Server Gateway Interface) √© um padr√£o para servidores web e aplica√ß√µes Python se comunicarem. **Gunicorn** √© um servidor WSGI que pode melhorar a performance do Flask. Usar o Gunicorn traz os seguintes benef√≠cios:

‚úÖ Diferente do servidor de desenvolvimento do Flask, que processa apenas uma requisi√ß√£o por vez, o Gunicorn pode lidar com v√°rias conex√µes simult√¢neas, tornando a aplica√ß√£o mais eficiente.\
‚úÖ O Gunicorn pode ser executado atr√°s de um proxy reverso como o Nginx ou Apache, que pode servir arquivos est√°ticos e lidar com tarefas de balanceamento de carga.

Em produ√ß√£o, ao inv√©s de rodar `python app.py`, use **Gunicorn** para melhorar a performance:  
```sh
pip install gunicorn
gunicorn -w 4 -b 0.0.0.0:5000 app:app
```
Isso inicia 4 "workers", permitindo que v√°rias requisi√ß√µes sejam processadas ao mesmo tempo.

‚úÖ Se houver mais de 4 requisi√ß√µes simult√¢neas, elas entram na fila e esperam um worker ficar dispon√≠vel.\
‚úÖ Se o servidor tiver mais CPU/RAM, voc√™ pode aumentar o n√∫mero de workers.\
‚úÖ Se o n√∫mero de requisi√ß√µes for muito alto e os workers demorarem para processar, a fila pode ficar sobrecarregada, causando lentid√£o ou erros 502/504 (Bad Gateway, Timeout).\
‚úÖ O Nginx pode ajudar a gerenciar conex√µes e servir arquivos est√°ticos, reduzindo a carga do Gunicorn.

Se a aplica√ß√£o faz muitas opera√ß√µes de entrada e sa√≠da (consultas SQL, chamadas HTTP externas), aumentar os workers melhora o desempenho. F√≥rmula Geral: **2 √ó CPUs + 1** (ex: 4 CPUs ‚Üí 9 workers).

---

# **2Ô∏è‚É£ Escalabilidade Horizontal (M√∫ltiplas Inst√¢ncias)**
A escalabilidade **horizontal** significa rodar v√°rias c√≥pias da aplica√ß√£o para distribuir o tr√°fego.

### **üîß Usando Load Balancer**
Se o tr√°fego aumentar, voc√™ pode rodar **m√∫ltiplas inst√¢ncias** e usar um **Load Balancer** para distribuir as requisi√ß√µes.  

üîπ No **Railway, Render ou Heroku**, basta aumentar as "inst√¢ncias" na configura√ß√£o do servi√ßo.  
üîπ Se estiver em um **VPS (AWS, DigitalOcean, Brdrive)**, pode usar o **NGINX** como proxy reverso.

Exemplo de configura√ß√£o NGINX para distribuir o tr√°fego entre 2 inst√¢ncias Flask:

```nginx
upstream flask_app {
    server 127.0.0.1:5000;
    server 127.0.0.1:5001;
}

server {
    listen 80;
    location / {
        proxy_pass http://flask_app;
    }
}
```
Isso envia requisi√ß√µes para m√∫ltiplas inst√¢ncias Flask rodando nas portas **5000** e **5001**.

---

# **3Ô∏è‚É£ Usando Containers (Docker e Kubernetes)**
Outra maneira de escalar √© usar **Docker** e **Kubernetes** para gerenciar m√∫ltiplas r√©plicas.

### **üîß Criando um Dockerfile**
Crie um arquivo `Dockerfile` na raiz do projeto:  
```dockerfile
# Usa a vers√£o leve do Python (Alpine)
FROM python:3.9-alpine
# Define o diret√≥rio de trabalho dentro do cont√™iner
WORKDIR /app
# Copia os arquivos necess√°rios para o cont√™iner
COPY . .
# Instala as depend√™ncias necess√°rias (usa --no-cache para evitar arquivos desnecess√°rios)
RUN pip install --no-cache-dir -r requirements.txt
# Exp√µe a porta 5000 para acesso externo
EXPOSE 5000
# Comando para iniciar a aplica√ß√£o usando Gunicorn
CMD ["gunicorn", "-w", "4", "-b", "0.0.0.0:5000", "app:app"]
```
Agora, **crie e rode o container**:  
```sh
docker build -t flask-app .
docker run -p 5000:5000 flask-app
```
Se quiser escalar com **Kubernetes**, pode usar `kubectl scale` para rodar **m√∫ltiplas c√≥pias** do container.

---

# **4Ô∏è‚É£ Banco de Dados Externo**
Usar **SQLite** em produ√ß√£o n√£o √© recomendado. Para escalar, use um banco como:  
‚úÖ **PostgreSQL** (ex: AWS RDS, Supabase, Railway, Render)  
‚úÖ **MySQL** (ex: PlanetScale)  

### **üîß Exemplo de Conex√£o PostgreSQL**
1Ô∏è‚É£ Instale o driver:  
```sh
pip install psycopg2
```
2Ô∏è‚É£ Atualize `connect_db()` no `app.py`:  
```python
import psycopg2
def connect_db():
    return psycopg2.connect(
        dbname="meubanco",
        user="usuario",
        password="senha",
        host="servidor.externo.com",
        port=5432
    )
```
Isso melhora a escalabilidade, pois v√°rias inst√¢ncias Flask podem acessar o mesmo banco.

---

# **5Ô∏è‚É£ Cache para Melhorar Performance**
Usar um **cache** evita que consultas repetidas sobrecarreguem o banco.

‚úÖ **Redis**: √ìtimo para armazenar resultados de consultas frequentes.  
‚úÖ **Memcached**: Boa op√ß√£o para melhorar tempos de resposta.  

### **üîß Usando Redis**
Instale a biblioteca Python:
```sh
pip install redis
```
No `app.py`, adicione um cache:
```python
import redis
cache = redis.Redis(host='localhost', port=6379, db=0)

@app.route('/')
def index():
    tasks = cache.get('tasks')
    if not tasks:
        con = connect_db()
        cur = con.cursor()
        cur.execute("SELECT * FROM tasks")
        tasks = cur.fetchall()
        con.close()
        cache.set('tasks', str(tasks), ex=30)  # Expira em 30s
    return render_template("index.html", tasks=eval(tasks))
```
Isso reduz a carga no banco de dados.

---

# **6Ô∏è‚É£ Otimiza√ß√µes de C√≥digo**

Vamos fazer mudan√ßas para testar a escalabilidade da aplica√ß√£o.

### Database Init

Vamos fazer uma altera√ß√£o no script `init_db.py` para criar o banco de dados em um diret√≥rio separado. Criamos um diret√≥rio `data` e alteramos o script para criar o banco de dados em `data/database.db`.

```sh
mkdir data
```

```python
import sqlite3

con = sqlite3.connect("data/database.db")
cur = con.cursor()
cur.execute("""
CREATE TABLE tasks (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    task TEXT NOT NULL,
    completed INTEGER DEFAULT 0
)
""")
con.commit()
con.close()

print("Banco de dados criado com sucesso!")
```

Em seguida, vamos alterar o `app.py` para conectar ao banco de dados no diret√≥rio `data`. Al√©m disso, vamos adicionar um log para cada requisi√ß√£o recebida. Isso nos ajudar√° a identificar o servidor que est√° processando a requisi√ß√£o.

### app.py
```python
from flask import Flask, render_template, request, redirect
import socket
import os
import logging
import sqlite3

app = Flask(__name__)
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@app.before_request
def log_request_info():
    hostname = socket.gethostname()
    port = os.environ.get('PORT', '5000')  # Pega a porta do ambiente ou usa 5000 como padr√£o
    logger.info(f"Requisi√ß√£o recebida em {hostname} na porta {port}")

def connect_db():
    # return sqlite3.connect("database.db")
    db_path = '/app/db/database.db'
    conn = sqlite3.connect(db_path)
    conn.row_factory = sqlite3.Row
    return conn

@app.route('/env')
def env():
    return str(os.environ)

@app.route('/oi')
def hello():
    hostname = socket.gethostname()
    port = os.environ.get('PORT', '5000')  # Pega a porta do ambiente ou usa 5000 como padr√£o
    logger.info(f"Requisi√ß√£o recebida em {hostname} na porta {port}")
    return f"Hello from {hostname} on port {port}!\n"

@app.route('/')
def index():
    con = connect_db()
    cur = con.cursor()
    cur.execute("SELECT * FROM tasks")
    tasks = cur.fetchall()
    con.close()
    return render_template("index.html", tasks=tasks)

@app.route('/add', methods=['POST'])
def add_task():
    task = request.form['task']
    con = connect_db()
    cur = con.cursor()
    cur.execute("INSERT INTO tasks (task, completed) VALUES (?, ?)", (task, 0))
    con.commit()
    con.close()
    return redirect('/')

@app.route('/delete/<int:id>')
def delete_task(id):
    con = connect_db()
    cur = con.cursor()
    cur.execute("DELETE FROM tasks WHERE id=?", (id,))
    con.commit()
    con.close()
    return redirect('/')

@app.route('/complete/<int:id>')
def complete_task(id):
    con = connect_db()
    cur = con.cursor()
    cur.execute("UPDATE tasks SET completed = 1 WHERE id=?", (id,))
    con.commit()
    con.close()
    return redirect('/')

if __name__ == "__main__":
    app.run(debug=True)
```

## Come√ßando com Docker

Vamos testar temporariamente uma imagem Docker para verificar se tudo est√° funcionando corretamente. Para isso, vamos usar a imagem `crccheck/hello-world` que √© um servidor HTTP simples. Podemos perceber que o par√¢metro `--rm` remove o container ap√≥s a execu√ß√£o.

```sh
# https://hub.docker.com/r/crccheck/hello-world/
docker run --rm --name web-test -p 1234:8000 crccheck/hello-world
```

### Nginx

Vamos adicionar um servidor de backup ao nosso cluster. Para isso, vamos usar o **Busybox** como um servidor HTTP simples. O **Busybox** √© uma imagem leve que cont√©m v√°rias ferramentas comuns do Linux. Vamos usar o **httpd** do Busybox para servir arquivos est√°ticos.

```bash
# Define o usu√°rio sob o qual o Nginx ser√° executado. 'nginx' √© um usu√°rio padr√£o criado para rodar o servi√ßo
# de forma segura, evitando privil√©gios de root e reduzindo riscos de seguran√ßa.
user nginx;

# Define o n√∫mero de processos trabalhadores (workers). 'auto' ajusta automaticamente com base no n√∫mero de
# n√∫cleos da CPU, otimizando o uso de recursos para lidar com m√∫ltiplas conex√µes.
worker_processes auto;

# Especifica o caminho do arquivo de log de erros e o n√≠vel de severidade. 'warn' registra mensagens de aviso
# ou mais graves, ajudando a identificar problemas sem sobrecarregar o log com detalhes triviais.
error_log /var/log/nginx/error.log warn;

# Define o arquivo onde o PID (ID do processo) do Nginx √© armazenado. Isso √© usado pelo sistema para gerenciar
# o processo (ex.: parar ou reiniciar o servidor).
pid /var/run/nginx.pid;

# Bloco 'events' configura como o Nginx gerencia eventos de rede, como conex√µes de clientes.
events {
    # Define o n√∫mero m√°ximo de conex√µes simult√¢neas por processo trabalhador. 1024 √© um valor padr√£o razo√°vel,
    # mas pode ser aumentado em servidores com mais carga ou recursos.
    worker_connections 1024;
}

# Bloco 'http' cont√©m configura√ß√µes globais para o protocolo HTTP/HTTPS.
http {
    # Inclui um arquivo externo que associa extens√µes de arquivos (ex.: .html, .jpg) a tipos MIME, permitindo
    # que o Nginx informe corretamente aos navegadores como interpretar os arquivos enviados.
    include /etc/nginx/mime.types;

    # Define o tipo MIME padr√£o para arquivos sem extens√£o mapeada. 'application/octet-stream' √© um tipo gen√©rico
    # que indica um fluxo de bytes brutos, deixando a interpreta√ß√£o para o cliente.
    default_type application/octet-stream;

    # Ativa o uso de 'sendfile', uma chamada de sistema eficiente que transfere arquivos diretamente do disco para
    # a rede, reduzindo a sobrecarga ao evitar c√≥pias na mem√≥ria do usu√°rio.
    sendfile on;

    # Define o tempo (em segundos) que uma conex√£o persistente (keep-alive) ser√° mantida aberta. 65 segundos √© um
    # valor equilibrado que melhora a performance ao reutilizar conex√µes, mas evita desperd√≠cio de recursos.
    keepalive_timeout 65;

    # Define um grupo de servidores upstream (backend) chamado 'flask_app'. O Nginx balancear√° as requisi√ß√µes entre
    # esses servidores usando um algoritmo padr√£o (round-robin, a menos que configurado de outra forma).
    upstream flask_app {
        # Servidor prim√°rio na porta 5000 (app1). 'max_fails=3' e 'fail_timeout=30s' definem toler√¢ncia a falhas:
        # ap√≥s 3 falhas em 30 segundos, o servidor √© temporariamente removido do balanceamento.
        server app1:5000 max_fails=3 fail_timeout=30s;

        # Segundo servidor prim√°rio na porta 5001 (app2), com as mesmas regras de toler√¢ncia a falhas.
        server app2:5001 max_fails=3 fail_timeout=30s;

        # Servidor de backup na porta 3000 (app3). S√≥ √© usado se os servidores prim√°rios estiverem indispon√≠veis,
        # funcionando como uma camada extra de resili√™ncia.
        server app3:3000 backup;
    }

    # Primeiro bloco 'server': lida com requisi√ß√µes HTTP na porta 80 e redireciona para HTTPS.
    server {
        # Escuta na porta 80, padr√£o para HTTP, permitindo que o servidor receba requisi√ß√µes n√£o seguras.
        listen 80;

        # Define o nome do servidor. 'localhost' √© usado para testes locais; em produ√ß√£o, seria um dom√≠nio real.
        server_name localhost;

        # Redireciona todas as requisi√ß√µes para HTTPS com um c√≥digo 301 (redirecionamento permanente), melhorando
        # a seguran√ßa ao for√ßar o uso de conex√µes criptografadas.
        return 301 https://$host$request_uri;
    }

    # Segundo bloco 'server': lida com requisi√ß√µes HTTPS na porta 443 com suporte a HTTP/2.
    server {
        # Escuta na porta 443 (padr√£o para HTTPS) com SSL ativado e HTTP/2 habilitado. HTTP/2 melhora a efici√™ncia
        # com multiplexa√ß√£o e compress√£o de cabe√ßalhos, mas exige SSL/TLS.
        listen 443 ssl http2;

        # Nome do servidor, novamente 'localhost' para testes locais. Em produ√ß√£o, use seu dom√≠nio (ex.: example.com).
        server_name localhost;

        # Caminho para o certificado SSL (inclui o certificado p√∫blico e a cadeia de certifica√ß√£o). Aqui, usamos um
        # certificado autoassinado gerado localmente.
        ssl_certificate /etc/letsencrypt/fullchain.pem;

        # Caminho para a chave privada correspondente ao certificado. Deve ser mantida segura e nunca exposta.
        ssl_certificate_key /etc/letsencrypt/privkey.pem;

        # Define os protocolos SSL/TLS suportados. TLSv1.2 e TLSv1.3 s√£o vers√µes modernas e seguras; vers√µes mais
        # antigas (ex.: SSLv3) s√£o evitadas por vulnerabilidades.
        ssl_protocols TLSv1.2 TLSv1.3;

        # Prioriza as cifras definidas pelo servidor em vez das prefer√™ncias do cliente, aumentando a seguran√ßa ao
        # garantir o uso de op√ß√µes fortes.
        ssl_prefer_server_ciphers on;

        # Lista de cifras criptogr√°ficas permitidas. 'EECDH+AESGCM:EDH+AESGCM' s√£o op√ß√µes modernas e seguras,
        # compat√≠veis com HTTP/2 e otimizadas para desempenho e prote√ß√£o.
        ssl_ciphers EECDH+AESGCM:EDH+AESGCM;

        # Bloco 'location' define como tratar requisi√ß√µes para a raiz ('/') do site.
        location / {
            # Encaminha as requisi√ß√µes para o grupo upstream 'flask_app', delegando o processamento aos servidores
            # backend (app1, app2 ou app3).
            proxy_pass http://flask_app;

            # Define cabe√ßalhos HTTP enviados ao backend para preservar informa√ß√µes do cliente:
            # 'Host' mant√©m o dom√≠nio original da requisi√ß√£o, essencial para aplica√ß√µes que dependem dele.
            proxy_set_header Host $host;

            # 'X-Real-IP' envia o IP real do cliente ao backend, √∫til para logs ou autentica√ß√£o.
            proxy_set_header X-Real-IP $remote_addr;

            # 'X-Forwarded-For' adiciona o IP do cliente √† lista de proxies, permitindo rastreamento em cen√°rios com
            # m√∫ltiplos proxies.
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

            # 'X-Forwarded-Proto' informa o protocolo original (http ou https), importante para aplica√ß√µes que precisam
            # saber se a requisi√ß√£o inicial foi segura.
            proxy_set_header X-Forwarded-Proto $scheme;

            # Define o tempo m√°ximo (em segundos) para estabelecer a conex√£o com o backend. 10 segundos √© um valor
            # baixo, exigindo respostas r√°pidas ou falhando a requisi√ß√£o.
            proxy_connect_timeout 10;

            # Limita o tempo para enviar dados ao backend, evitando travamentos se o backend estiver lento.
            proxy_send_timeout 10;

            # Limita o tempo para receber uma resposta do backend, garantindo que requisi√ß√µes demoradas sejam encerradas.
            proxy_read_timeout 10;

            # Define o tamanho m√°ximo do corpo da requisi√ß√£o (ex.: uploads). '10M' (10 megabytes) protege contra abusos,
            # como envio de arquivos muito grandes.
            client_max_body_size 10M;
        }
    }
}
```

> **Artigo**: [Tune nginx performance](https://medium.com/@tynwthpq/tune-nginx-performance-fbba6a7f4a25)

### Docker Compose

Vamos usar o **Docker Compose** para gerenciar os containers. O Docker Compose √© uma ferramenta que permite definir e executar aplicativos Docker multi-container. Ele usa um arquivo YAML para configurar os servi√ßos, volumes e redes. No arquivo `docker-compose.yml`, definimos os servi√ßos `app1`, `app2`, `app3` e `nginx`.

```yaml
services:
  app1:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: app1
    environment:
      - PORT=5000
    volumes:
      - ./data:/app/db
    depends_on:
      cert-generator:
        condition: service_healthy  # S√≥ inicia ap√≥s o certificado estar pronto

  app2:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: app2
    environment:
      - PORT=5001
    volumes:
      - ./data:/app/db
    depends_on:
      cert-generator:
        condition: service_healthy  # S√≥ inicia ap√≥s o certificado estar pronto

  app3:
    image: busybox:latest
    container_name: app3
    volumes:
      - ./backup:/var/www
    command: ["httpd", "-f", "-p", "3000", "-h", "/var/www"]
    depends_on:
      cert-generator:
        condition: service_healthy  # S√≥ inicia ap√≥s o certificado estar pronto

  nginx:
    image: nginx:latest
    container_name: nginx
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./certs:/etc/letsencrypt
    ports:
      - "80:80"   # Mapeia para 8080 no Windows/WSL
      - "443:443"  # Mapeia para 8443 no Windows/WSL
    depends_on:
      app1:
        condition: service_started
      app2:
        condition: service_started
      app3:
        condition: service_started
      cert-generator:
        condition: service_healthy  # S√≥ inicia ap√≥s o certificado estar pronto

  cert-generator:
    image: alpine:latest
    container_name: cert-generator
    volumes:
      - ./certs:/etc/letsencrypt
    command: >
      /bin/sh -c "
        apk add openssl &&
        openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/letsencrypt/privkey.pem -out /etc/letsencrypt/fullchain.pem -subj '/CN=localhost' &&
        chown -R 101:101 /etc/letsencrypt &&
        tail -f /dev/null  # Mant√©m o container ativo ap√≥s gerar os certificados
      "
    healthcheck:
      test: ["CMD", "test", "-f", "/etc/letsencrypt/fullchain.pem"]  # Verifica se o certificado foi gerado
      interval: 5s
      timeout: 3s
      retries: 3
      start_period: 5s

  # Servi√ßo tempor√°rio para gerar certificados com Certbot
  # certbot:
  #   image: certbot/certbot:latest  # Imagem oficial do Certbot
  #   volumes:
  #     - ./certs:/etc/letsencrypt   # Armazena os certificados no diret√≥rio ./certs do host
  #   entrypoint: /bin/sh           # Substitui o entrypoint padr√£o para rodar comandos manuais
  #   command: -c "certbot certonly --standalone -d example.com -d www.example.com --email fabricio.bizotto@gmail.com --agree-tos --no-eff-email"
  #   # Comando para gerar certificados no modo standalone (substitua example.com e seuemail@example.com)
```

**Detalhes**:
- **app1** e **app2** s√£o inst√¢ncias do Flask rodando na porta 5000 e 5001, respectivamente.
- **app3** √© um servidor de backup usando o Busybox para servir arquivos est√°ticos na porta 3000.
- **nginx** √© o servidor Nginx que balanceia a carga entre app1, app2 e app3.
- O volume `./data` √© montado em `/app/db` nos containers app1 e app2 para persistir o banco de dados.
- O volume `./backup` √© montado em `/var/www` no container app3 para servir arquivos est√°ticos.
- O volume `./nginx/nginx.conf` √© montado em `/etc/nginx/nginx.conf` no container nginx para configurar o Nginx.
- O Nginx depende dos servi√ßos app1, app2 e app3, garantindo que eles sejam iniciados primeiro.
- O Nginx escuta na porta 80 e encaminha as requisi√ß√µes para os servidores backend.
- O servi√ßo `cert-generator` gera certificados SSL autoassinados para o Nginx.
- O servi√ßo `cert-generator` s√≥ inicia ap√≥s gerar os certificados e mant√©m o container ativo com `tail -f /dev/null`.
- O servi√ßo `cert-generator` tem um healthcheck que verifica se o certificado foi gerado.

### Dockerfile
```dockerfile
# Usa a vers√£o leve do Python (Slim)
FROM python:3.9-slim
# Define o diret√≥rio de trabalho dentro do cont√™iner
WORKDIR /app

# Instala as depend√™ncias necess√°rias
RUN apt update && apt install -y net-tools bash

# Copia os arquivos necess√°rios para o cont√™iner
COPY . .
# Instala as depend√™ncias necess√°rias (usa --no-cache para evitar arquivos desnecess√°rios)
RUN pip install --no-cache-dir -r requirements.txt
# Comando para iniciar a aplica√ß√£o usando Gunicorn
CMD ["sh", "-c", "gunicorn --workers 3 --bind 0.0.0.0:${PORT:-5000} app:app"]
```

### Hosts

Estamos usando o dom√≠nio `desweb.local` para testar a aplica√ß√£o. Adicione o seguinte ao arquivo `hosts`:

```sh
127.0.0.1 desweb.local
```

> Se estiver usando WSL, o arquivo `hosts` est√° em `C:\Windows\System32\drivers\etc\hosts`. Voc√™ precisar√° editar como administrador. No Linux, o arquivo est√° em `/etc/hosts`.

### Comandos
```sh
docker ps
docker stats
docker compose ps
docker compose up -d --build
docker compose down
docker compose logs -f app1
docker compose logs -f app2
docker compose logs -f nginx --tail 100
docker-compose up -d --force-recreate nginx # For√ßa a recria√ß√£o do container
docker exec -it nginx /bin/bash # Acessa o container Nginx
docker exec nginx ls -l /etc/letsencrypt # Lista os certificados
docker exec -it app1 bash -c "netstat -tuln | grep 5000"
docker exec -it app2 bash -c "netstat -tuln | grep 5001"
curl -k http://localhost/oi  # -k: erro 301
curl -k https://localhost/oi  # -k: Ignora erros de certificado
for i in {1..10}; do curl -k https://localhost/oi; done

# Network
docker network ls
docker network inspect monolito_default
docker inspect nginx | grep IPAddress
docker inspect app1 | grep IPAddress
docker inspect app2 | grep IPAddress
docker inspect app3 | grep IPAddress
docker inspect cert-generator | grep IPAddress
docker port nginx
docker compose exec nginx curl http://app1:5000
docker compose exec nginx curl http://app2:5001/oi
```

### Para parar um container 

```sh
docker compose stop app1
docker compose stop app2
# assim testamos o backup
```

### Limpeza

```sh
docker compose down
docker system prune -a # Remove todos os containers, imagens e volumes n√£o utilizados, ou seja, limpa tudo
```